- sm , 流式多处理器，是GPU架构的核心；
  ```xml
    1. GPU中每个SM都能支持数百个线程并发执行，每个GPU通常有多个SM
    2. 当一个核函数的网格被启动的时候，多个block会被同时分配给可用的SM上执行。
    3. 当一个blcok被分配给一个SM后，他就只能在这个SM上执行了，不可能重新分配到其他SM上了
    4. 在SM上同一个块内的多个线程进行线程级别并行，而同一线程内，指令利用指令级并行将单个线程处理成流水线
  ```
- sp ， 最基本的处理单元，也称为cuda core，最后具体的指令和任务都是在SP上处理的

- 线程束
  ```xml
  1. CUDA 采用单指令多线程SIMT架构管理执行线程，不同设备有不同的线程束大小，但是到目前为止基本所有设备都是维持在32
  2. 每个SM上有多个block，一个block有多个线程（可以是几百个，但不会超过某个最大值），但是从机器的角度，在某时刻T，SM上只执行一个线程束，也就是32个线程在同时同步执行
  3. 线程束中的每个线程执行同一条指令，包括有分支的部分
  ```
- SIMD vs SIMT
    ```xml
    1. 单指令多数据的执行属于向量机,所有分支必须同时执行相同的指令，必须执行没有例外
    2. 单指令多线程SIMT就更加灵活,某些线程可以选择不执行,这样SIMT就保证了线程级别的并行，而SIMD更像是指令级别的并行
        - 每个线程都有自己的指令地址计数器
        - 每个线程都有自己的寄存器状态
        - 每个线程可以有一个独立的执行路径
    ```

# CUDA编程组件与逻辑
   ![](./img/3_2.png)

   1. SM中共享内存，和寄存器是关键的资源，线程块中线程通过共享内存和寄存器相互通信协调
   2. 并行就会引起竞争，多线程以未定义的顺序访问同一个数据，就导致了不可预测的行为，CUDA只提供了一种块内同步的方式，==块之间没办法同步==
   3. 同一个SM上可以有不止一个常驻的线程束，有些在执行，有些在等待，他们之间状态的转换是不需要开销的

# GPU架构

## Fermi 架构

## Kepler 架构